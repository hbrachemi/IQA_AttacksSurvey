{"cells":[{"cell_type":"code","execution_count":null,"id":"9c7538b6","metadata":{"id":"9c7538b6"},"outputs":[],"source":["from architectures import *\n","from dataloader import iqa_dataset\n","from config import *\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import copy"]},{"cell_type":"code","execution_count":null,"id":"269e1cb6","metadata":{"id":"269e1cb6"},"outputs":[],"source":["db = \"../Databases/tid2013/\""]},{"cell_type":"code","execution_count":null,"id":"19f1d564","metadata":{"id":"19f1d564"},"outputs":[],"source":["scale = int(input()) #Scale of ground truth quality score used in the dataset"]},{"cell_type":"code","execution_count":null,"id":"746266b9","metadata":{"id":"746266b9"},"outputs":[],"source":["if db.split(\"/\")[-2] == \"tid2013\":\n","    scale2 = 10\n","elif db.split(\"/\")[-2] == \"koniq\":\n","    scale2 = 5\n","elif db.split(\"/\")[-2] == \"livew\":\n","    scale2 = 100\n","else:\n","    print(\"SCALE WASNT DEFINED\")\n","if scale != scale2:\n","        print(\"Check scale value!\")"]},{"cell_type":"code","execution_count":null,"id":"47dbcfe6","metadata":{"id":"47dbcfe6"},"outputs":[],"source":["batch_size = 1\n","\n","train_data=iqa_dataset(part='train',labels_path=db+'scores.pickle' ,db_path=db+'Images/',\n","                 ids_path=db+'/IDs.pickle',\n","                       transform=transforms.Compose([transforms.ToTensor()]))\n","\n","val_data = iqa_dataset(part='test',labels_path=db+'scores.pickle' ,db_path=db+'Images/',\n","                 ids_path=db+'IDs.pickle',\n","                       transform=transforms.Compose([transforms.ToTensor()]))\n","\n","print(f\"Length of Train Data : {len(train_data)}\")\n","print(f\"Length of Validation Data : {len(val_data)}\")\n","\n","train_dl = DataLoader(train_data, batch_size, shuffle = True)\n","val_dl = DataLoader(val_data,1,shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"id":"8127942a","metadata":{"scrolled":false,"id":"8127942a"},"outputs":[],"source":["# Initialize the model for this run\n","model = initialize_model('inception',False,True)"]},{"cell_type":"code","execution_count":null,"id":"d0940e5c","metadata":{"id":"d0940e5c"},"outputs":[],"source":["model=FC(model,2,1024,0.25,'inception')"]},{"cell_type":"code","execution_count":null,"id":"da06d445","metadata":{"id":"da06d445"},"outputs":[],"source":["weights_path = '../pretrained/iqaModel_tid_inception.pth'\n","model.fc.load_state_dict(torch.load(weights_path, map_location = device))\n","model = model.eval()"]},{"cell_type":"code","execution_count":null,"id":"a3cce680","metadata":{"id":"a3cce680"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"5730a4dc","metadata":{"id":"5730a4dc"},"outputs":[],"source":["from attacks.fgm import fast_gradient_method \n","from attacks.pgd import projected_gradient_descent \n","\n","from tqdm import tqdm\n","import numpy as np\n","\n","from eval_funct import *"]},{"cell_type":"code","execution_count":null,"id":"9cfdf507","metadata":{"scrolled":true,"id":"9cfdf507"},"outputs":[],"source":["SRCC,KRCC,PLCC,RMSE,fr,mos = evaluate(val_dl,scale,model,normalize_imagenet, None ,None)\n","print(\"------------------- performance of the NR IQA metric: -------------------\")\n","print(\"SRCC: \",SRCC)\n","print(\"PLCC: \",PLCC)\n","print(\"KRCC: \",KRCC)\n","print(\"RMSE: \",RMSE)"]},{"cell_type":"code","execution_count":null,"id":"a75ce784","metadata":{"id":"a75ce784"},"outputs":[],"source":["#Define parametters and attacks\n","iterations = [10]\n","epsilons = [0.001]#,0.01,0.1]\n","attacks = [\"pgd\"]#[\"bim\",\"pgd\",\"fgm\"]\n","losses = [\"mse(y_tielda,y)\"]#,'mse','sqr(max-y)']"]},{"cell_type":"code","execution_count":null,"id":"9a0c8e8f","metadata":{"id":"9a0c8e8f"},"outputs":[],"source":["#Initialization\n","perf = dict()\n","epsilon_dict = dict()\n","iter_dict = dict()\n","attack_dict = dict()\n","loss_dict = dict()\n","results = dict()"]},{"cell_type":"code","execution_count":null,"id":"ea75207d","metadata":{"id":"ea75207d"},"outputs":[],"source":["perf['srcc'] = str(SRCC)\n","perf['plcc'] = str(PLCC)\n","perf['krcc'] = str(KRCC)\n","perf['rmse'] = str(RMSE)\n","results['original_performance'] = copy.deepcopy(perf)"]},{"cell_type":"code","execution_count":null,"id":"6d2cf540","metadata":{"scrolled":true,"id":"6d2cf540"},"outputs":[],"source":["import pyiqa\n","fr_metric = pyiqa.create_metric('lpips', device=device,as_loss=True)"]},{"cell_type":"code","execution_count":null,"id":"723bb19d","metadata":{"scrolled":true,"id":"723bb19d"},"outputs":[],"source":["loss_fct = torch.nn.MSELoss()\n","y_target = torch.tensor(1).float().to(device)\n","y_target = torch.unsqueeze(y_target,0)\n","y_target = torch.unsqueeze(y_target,0)\n","\n","\n","\n","for loss in losses:\n","    if loss in ['mse','mse(y_tielda,y)']:\n","        targeted = False\n","    else:\n","        targeted = True\n","    for attack in attacks:\n","        fgm_passage = False\n","        for it in iterations:\n","            if attack == 'fgm' and fgm_passage:\n","                continue\n","            else:\n","                fgm_passage = True\n","\n","\n","            epsilon_dict = dict()\n","\n","\n","            for epsilon in epsilons: \n","                #noise_list = []\n","                \n","                y_adv_list = []\n","                y = []\n","                fr = []\n","\n","\n","                for i ,[im, label] in enumerate(tqdm(val_dl)):\n","                    im = im.to(device)\n","\n","                    if targeted == False:\n","                      if loss == 'mse':\n","                        #if mos are available\n","                        y_target = torch.unsqueeze(label.float().to(device)/scale,0)\n","                      if loss == 'mse(y_tielda,y)':\n","                        #estimate mos\n","                        y_pred = float(model(normalize_imagenet(im)).detach().cpu())*scale\n","                        s = 0\n","                        for counter in range(10):        \n","                            s += np.random.normal(y_pred,3*float(results['original_performance']['rmse']),1)\n","                        s /= 10\n","                        s =torch.tensor(s)\n","                        y_target = torch.unsqueeze(s.float().to(device)/scale,0)\n","                        \n","                    y.append(float(label.detach().cpu()))\n","                    if attack == \"fgm\":\n","                        img_adv = fast_gradient_method(model,im,epsilon,np.inf,\n","                                                       preprocess=normalize_imagenet,y=y_target,\n","                                                       loss_fn=loss_fct,targeted=targeted)\n","                        \n","                        #x_adv_list.append(img_adv)\n","                    if attack == \"pgd\":\n","                        img_adv = projected_gradient_descent(model,im,epsilon,eps_iter=0.001,preprocess=normalize_imagenet,\n","                                                             nb_iter=it,norm=np.inf,y=y_target,loss_fn=loss_fct,\n","                                                             targeted=targeted,rand_init=True)\n","                        #x_adv_list.append(img_adv)\n","                    if attack == \"bim\":\n","                        x0 = torch.clone(im)\n","                        for j in range(it):\n","                            x0 = fast_gradient_method(model,x0,epsilon,np.inf,y=y_target,loss_fn=loss_fct,targeted=targeted,preprocess=normalize_imagenet)\n","                        img_adv = x0\n","                   \n","\n","                    y_adv_list.append(float(model(normalize_imagenet(img_adv)).detach().cpu()*scale))\n","                    fr.append(fr_metric(im,img_adv).cpu().detach())\n","                SRCC,KRCC,PLCC,RMSE = compute_metrics(y,y_adv_list)\n","\n","\n","                perf['srcc'] = str(SRCC)\n","                perf['krcc'] = str(KRCC)\n","                perf['plcc'] = str(PLCC)\n","                perf['rmse'] = str(RMSE)\n","                perf['lpips'] = str(np.mean(fr))\n","                epsilon_dict[str(epsilon)] = copy.deepcopy(perf)\n","                print(f'{loss}\\n {attack}\\n  {it}\\n   {epsilon_dict}')\n","               \n","            iter_dict[str(it)] = copy.deepcopy(epsilon_dict)\n","        attack_dict[attack] = copy.deepcopy(iter_dict)\n","    loss_dict[loss] = copy.deepcopy(attack_dict)\n","    results['results'] = loss_dict\n","    \n","\n"]},{"cell_type":"code","execution_count":null,"id":"2ae9885a","metadata":{"id":"2ae9885a"},"outputs":[],"source":["#Save stats and performance measures\n","import yaml\n","f = 'tid_resnet.yaml'\n","with open(f, 'w') as outfile:\n","    yaml.dump(results, outfile, default_flow_style=False)"]},{"cell_type":"code","execution_count":null,"id":"c2503f9a","metadata":{"id":"c2503f9a"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}